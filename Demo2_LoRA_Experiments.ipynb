{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3add7b8b",
      "metadata": {
        "id": "3add7b8b"
      },
      "source": [
        "# LoRA experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12361c6e",
      "metadata": {
        "id": "12361c6e"
      },
      "source": [
        "## Introduction\n",
        "In this notebook, we will perform LoRA experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "85d1d7ef",
      "metadata": {
        "id": "85d1d7ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718903516735,
          "user_tz": 420,
          "elapsed": 12228,
          "user": {
            "displayName": "Axel Sirota",
            "userId": "02089179879199828401"
          }
        },
        "outputId": "d074d81f-749c-4616-9c54-9ca4d5063802"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting requests (from transformers)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: xxhash, typeguard, requests, pyarrow, dill, tensorflow_addons, multiprocess, datasets\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-16.1.0 requests-2.32.3 tensorflow_addons-0.23.0 typeguard-2.13.3 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers tensorflow datasets tensorflow_addons"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a5067cf",
      "metadata": {
        "id": "1a5067cf"
      },
      "source": [
        "## Load and Preprocess the  Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "XUiNfOux83Ec",
      "metadata": {
        "id": "XUiNfOux83Ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446,
          "referenced_widgets": [
            "34f34a45dfed47ee91888682f19374af",
            "af13ad89a9bc413b8f6f4cb2e7348343",
            "9a693620ca474bdcbaf18bbd5c0ead7d",
            "dd118d9e81434f13afd0b3098b03782a",
            "8012336dfe944978a73983c340a9b9be",
            "89d8c10ce19f4ae89ebb466ab981bd3b",
            "8216b34078b6401180608edf14ca1252",
            "712850daf43947b3b48f03b6afd5c678",
            "299f23b34fff4a0cacb4a5cd5a24a8eb",
            "ce09fc9c47bb41a594348452b57cf418",
            "447c82c13a1a4df2a68e922779528b34",
            "017ca40f2c7745c784f236a72971348e",
            "9a4c3b32c47a42edb77f28dc3553be15",
            "40d3d19674f547749c6f279202f55ea6",
            "71e5b44e9ef749d896e88ba8f62c6784",
            "7732bb88b1d54594b3156b1d7690721b",
            "b4c62bb225a540caa6c64060785cc8cb",
            "73cfd430c9c94be4a81c125c409c15ad",
            "c0a5f60b551e4739a97c7600f75aedf0",
            "25615474bc2d4d329576153b74ac41f9",
            "45dec2ba42db4c4d9d8783a728401d90",
            "b6372789105a4d688021258eb479f2e6",
            "8eb296c3b1c544feaa6cc219d9124d68",
            "91efc341727d448b851ab34d2b09e2d0",
            "fa978da24ac54c3d9d8164274dec3e9e",
            "bb45a5f683b74ece852e51369e7ae5ae",
            "a3c7224753c74840be2b623d74fae78e",
            "76e7d7630b7f47e896b7841bbfb742f8",
            "a02014c25aba4880b09800a1345b2c4a",
            "fa86339f57bf4e63ae70d7d55b8c0996",
            "4cf2ed30599f490aa5916ded2078a95d",
            "d15e47803ef04556ab8f403ae92ff5e1",
            "c77476b765b5423d954bf68314238788",
            "623f0a742bf04b659302dfcc6cb8be71",
            "95ac84c981af416cbac852fb2a4062b0",
            "2e74cda43443469598fdaf6d65a7c6ea",
            "52b5d134ff8b42ceaf017e57899ecd7e",
            "8921496ec053474fa507821173fe9cca",
            "c8ba0536e56c4e6ba2b705344424a399",
            "ff78dd443d1e4bd094591186a72f30f9",
            "0a8ead7d777d489686a1634b8fc0bae9",
            "f93f2969aa93478d9996c40e7b072749",
            "f5c0cf7531134fb3bf1b58bb23601fd0",
            "c457cf2e59e447b0837e16b82fdda8f0",
            "0a6b82ff9d8d4098b2a718f34345e601",
            "92ce7a95417b4c729f94132991105aa9",
            "43d240db0d9642b9b97aa4bed70de258",
            "5a8bd2d771e44c12b851d4c4c80e3211",
            "7b9db45b5d7a4b5d9d75ec60039a2a5e",
            "a494773cb934496b9717f286401937d0",
            "5d1a18007147443d9272094c35e09b56",
            "5ed41db3ec3143ec9fc5bee6ff3f4e57",
            "e62562238bc4424aa7b47265c676b944",
            "0ddce674718147dcab4657f0d0a983b4",
            "5c7faafe0bd24665bd84c3679e16d219",
            "09663962fef44b938c2b222d6b6eb9db",
            "263714f949744c96a62caea345d094c7",
            "a5843a33563b43e18d39ce58072208a4",
            "7f842bbda6d64373a782c13a9075751b",
            "548487eb91d248a5a3b3e0f54ebb5a13",
            "f835d0fbc5e241fd9fa8baf9eb38d9cd",
            "55e421dc9e0448769e770fec2209934e",
            "816da492944548e3987495329ae43321",
            "e541bfd12375483aba36429ed24b6785",
            "1f914a76052a4de0b4bba824ba823d50",
            "ac900e7dc5fd40daa7332e461de0fc09",
            "6ebd24a942d54d078788f648723e7e5b",
            "a095eebd45454e3ab5c31a846e0459a6",
            "c261a71cb1f9419795f03d569793e985",
            "12581860f39f4908970b4d6d4e53b4e7",
            "2bf8ed5ab9ec44e58e4e9cdab5cce625",
            "c89d4362dcbb465cb7efbeb57b32d5c8",
            "b5b96347c20e4fc79b9aafcd7743f658",
            "37f04e08dbea48b7828e354d1bf9416a",
            "f61e73b72f354834914b1ecbfef75e44",
            "a31d7635597a4b4cb79ec0113671fb36",
            "6ed2b179acdd4995a47294aa312448f1",
            "112baea76160470aa8c9f479b8856d32",
            "528b0ebf639c47938f7f249b0c741a43",
            "72a005a43f86405b90f368fa9424c190",
            "93c0c463a9464e16becef1f4eaf624ea",
            "8cb342c528f841ffb955b68bf8095516",
            "bba3d217bc694cc4895d10a39c8d82f4",
            "4c3f37233d2343a0bc02736d4fbf8f64",
            "5f36b4bb538c45788dd806c1d01b24a8",
            "265c1c441a36442eab7fb8ead7ac5f45",
            "e933e1bb0779463b8cdb86fd151c99db",
            "b2c6d5fab4a2406494e0580cd3fb336b",
            "29dd48737a6349e981515297cbf1c005",
            "337499d847f148fe8a745362fefa126b",
            "81913fd771404c918625af6060436962",
            "e8f023e23bfe46b69e5933f799cad210",
            "a4a22ccd71ee43268c46915ac2f81bda",
            "18c37e4f81264f20bcb718378b55ab32",
            "4e9387ea4686496ab073b05dce85eb71",
            "d643640001794c7ea776b89f6cc82efc",
            "f2d488d4246241dcad41073fbcf7520d",
            "11cb1b979265403cb031d64f046446e7",
            "ed90e2bec8ad42498a2aa9c500d21ba6"
          ]
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718903543382,
          "user_tz": 420,
          "elapsed": 26650,
          "user": {
            "displayName": "Axel Sirota",
            "userId": "02089179879199828401"
          }
        },
        "outputId": "7f1b2c6f-ba1a-4387-b7f2-44d0f5735dcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/11.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34f34a45dfed47ee91888682f19374af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/282M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "017ca40f2c7745c784f236a72971348e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/267M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8eb296c3b1c544feaa6cc219d9124d68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/277M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "623f0a742bf04b659302dfcc6cb8be71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/343k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a6b82ff9d8d4098b2a718f34345e601"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/475k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09663962fef44b938c2b222d6b6eb9db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/4548885 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ebd24a942d54d078788f648723e7e5b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/2169 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "112baea76160470aa8c9f479b8856d32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/2999 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29dd48737a6349e981515297cbf1c005"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'translation': {'de': 'Wiederaufnahme der Sitzungsperiode', 'en': 'Resumption of the session'}}\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the WMT16 English-German dataset\n",
        "dataset = load_dataset('wmt16', 'de-en')\n",
        "\n",
        "# Display an example\n",
        "print(dataset['train'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3a3ade7f",
      "metadata": {
        "id": "3a3ade7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "2d1a2fad9a95481bbf20381dca5b8d8f",
            "207a8264ff0747e4916fc70252502083",
            "a1919830d5a646afb1f571dbf770c556",
            "f5cfdb0bd5d04906a7f238567b07b1b9",
            "7c2a91f807584a57a9a0e607f58d7b85",
            "46316261c36842d7be604d950c78b2ce",
            "6e4398de257b4091bcc1fcd5f2851b55",
            "491e722a8889479e8228aea651333049",
            "e3282feb1b8045edb0d3b050df23fb57",
            "d174a9e43f4d418caeddc1f1e5798619",
            "872bb5ece671448aa19f035525cafb6b",
            "a27c6915c782431597d3ff81aaa121e5",
            "d4a48e83704840a396ccbb2289fd3fd0",
            "8b3701978e144192937db16731c62d81",
            "e5e31f3d66224fe591d111c3806b65a7",
            "67d06bb9380148968755caff2e160b98",
            "e6f767747c934b8eac62be0ad7dfe110",
            "ff89051afdf64d16a8b58caa229208b1",
            "648500030f014c4b9a5a751a8f9a79c8",
            "dd6da0b7ec544998850fd6ef5a768db9",
            "e0ceb1b0fcc843faa253ce68d793e754",
            "693104c703d24c9b80d83c95f46c6f5a",
            "83ed82bb4d064ff3929e29df75464e59",
            "750797010cea4101ab0eaaccd242b509",
            "9d250859a4934b2a95aa400b46629b30",
            "6d2c4de1d61a47fa84fbfda3258e0aa7",
            "d0460be2ae334d15a0f50ec30d8caa03",
            "97f80dc38659426190d3c07648eef552",
            "689abd1f42c1468b9a2bcc7b00a2c0da",
            "689064cf3031420ea64348be00be3e66",
            "a8bcc64b30f14415af21d0bad18bc61c",
            "82ff44b6cedf4b5b9711857c16f7b67f",
            "849b465498984f1cbb5d605820d912f7",
            "ee44523fc8434e26b9c6a32eb530255a",
            "7f30a8a631614ad99da31c0a2ccc499a",
            "c812e87ffa6a4a569b51e8e5983d0fe5",
            "f5d651c3a989467998d1d16be3125882",
            "476ec6872d804eb9b45895164b539924",
            "922c8a734a274695b003ff48650c4ad8",
            "09f98e33630f4a24a4d3db963851c625",
            "483d179f3f08422e8025bef402378055",
            "a3d14afcac7940f489480cdeee4ebf0d",
            "2f191acbf4094a66876c4b9fa2df2b9d",
            "d3119c7d566e4648ad2745b9c61f68c0"
          ]
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718903552776,
          "user_tz": 420,
          "elapsed": 9411,
          "user": {
            "displayName": "Axel Sirota",
            "userId": "02089179879199828401"
          }
        },
        "outputId": "a90164c9-a4b1-4eb2-d9da-4131445720ec"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d1a2fad9a95481bbf20381dca5b8d8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a27c6915c782431597d3ff81aaa121e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83ed82bb4d064ff3929e29df75464e59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee44523fc8434e26b9c6a32eb530255a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base')\n",
        "\n",
        "# Preprocess the dataset for input into the model\n",
        "def preprocess_data(examples):\n",
        "    inputs = [f'Translate English to German: {example[\"en\"]}' for example in examples['translation']]\n",
        "    targets = [example['de'] for example in examples['translation']]\n",
        "    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding='max_length', return_tensors='tf')\n",
        "    labels = tokenizer(targets, max_length=128, truncation=True, padding='max_length', return_tensors='tf').input_ids\n",
        "    model_inputs['labels'] = labels\n",
        "    decoder_inputs = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\")\n",
        "    model_inputs[\"decoder_input_ids\"] = decoder_inputs[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "girRYHMU8cnK",
      "metadata": {
        "id": "girRYHMU8cnK",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718903552776,
          "user_tz": 420,
          "elapsed": 20,
          "user": {
            "displayName": "Axel Sirota",
            "userId": "02089179879199828401"
          }
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b5d8d841",
      "metadata": {
        "id": "b5d8d841",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718903552777,
          "user_tz": 420,
          "elapsed": 19,
          "user": {
            "displayName": "Axel Sirota",
            "userId": "02089179879199828401"
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Replace the dense layers with LoRA layers\n",
        "class LoRALayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, dense, rank=4):\n",
        "        super().__init__()\n",
        "        self.dense = dense\n",
        "        self.rank = rank\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w_a = self.add_weight(shape=(input_shape[-1], self.rank),\n",
        "                                   initializer='random_normal',\n",
        "                                   trainable=True, name='w_a')\n",
        "        self.w_b = self.add_weight(shape=(self.rank, self.dense.units),\n",
        "                                   initializer='random_normal',\n",
        "                                   trainable=True, name='w_b')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        original_output = self.dense(inputs)\n",
        "        lora_output = tf.matmul(tf.matmul(inputs, self.w_a), self.w_b)\n",
        "        self.dense.trainable = False\n",
        "        return original_output + lora_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "LiRFWiJE_Dda",
      "metadata": {
        "id": "LiRFWiJE_Dda",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718903552777,
          "user_tz": 420,
          "elapsed": 18,
          "user": {
            "displayName": "Axel Sirota",
            "userId": "02089179879199828401"
          }
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fc3bc024",
      "metadata": {
        "id": "fc3bc024"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e67ad57d",
      "metadata": {
        "id": "e67ad57d"
      },
      "source": [
        "## Train the Model with Different Ranks and Batch Sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bed40bf8",
      "metadata": {
        "id": "bed40bf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e3dc91df8c8a4a70a710ace89b118af9",
            "479605327f50479298769d130bb0f526",
            "663e0099e66941a29d058edc75f0be27",
            "2d429c5ac8a64e438d70ef0b582e91bc",
            "31eabe618bac4c34873c5c0a2ba60a46",
            "fa8cb4c0d84e4f2ea606d03a9673caca",
            "164809fea4124e2e8cc8f4d5ffcaf7b1",
            "f63d693154f5433abe5740deab1777f1",
            "73355fce65584eb48387f4530c98107b",
            "ce34aa8239094cd99e175f46f0f679e8",
            "0400f150e5fa4798ab3f7d492005d78f",
            "3d1aa7c781b145119928bc8f39d99dc6",
            "a669cdb202844747bef45e077cda3f19",
            "10a2770890784347a12b901b942b3a1a",
            "d58ea6cb93cd44cb8f3719420805ed8c",
            "fbc9553f35e44e4d84298a1761a78d38",
            "99ad558e1fb54d6daf1b9c7ed1aa6667",
            "467aec075dc942d88d5092c22b3af867",
            "d055b5adc62b4bbb9087db96d60d6e91",
            "3feec74b318a4f2ea0c84858ed8efa72",
            "624ddb7c56bd43f3b632512ae04494eb",
            "b92f0dd92442436587fa0b518014bb99",
            "db30b1652c8446a29aa79cff1c5ec1d4",
            "40d7e56e7e32462fb24e6765c0a088f1",
            "0e8a833d26c640119bc68b85bfcd95e9",
            "d8c5aeb8c6de4c2596bf473b05376042",
            "4d761ec17d1041f3a1feaf78ff2a8148",
            "007d5d9556de4caf8fcf33451afe3a09",
            "af5d670b5d1a4b17934d0271551fe5f8",
            "72028ccb472d477ea28793f603f985a0",
            "b72f496997944a509a32ab49bf022098",
            "b81ed0cdd8d849ef86e930a867996492",
            "d69c2b850364466db8e247b1c6e1afee",
            "b9f0e60e80694234af6a3f238291f86b",
            "f7ad55124a7446faac50172e89c32ef2",
            "8ca54b4aa7e74bbaac8b9f245499488e",
            "f17c245d5f7d48f9ae706813c8414f96",
            "ccc34c9b31884eefa25c3a43bb1dd230",
            "2d964c68e7634637baa771e81aa857fd",
            "eb72b02ee0ca4f3e83fabd8126b74cc3",
            "820701bdb0794aed9f4a08e31f014a60",
            "a6207e9eec4f4294aeb0ecdbcd4fd28e",
            "f099bbfa67f04e56b8983a4b30a55785",
            "bc1bc9a07cd6464b8e61d2dff9cdffe1",
            "fdca1eb47cdd442a87d85cd37a69afa6",
            "e8fb6e5dfa1a4e4dbf708ae0ac84d72c",
            "fe1c41031a2348ce87b3ed517be92691",
            "11c963e926634401ad9ee79b61b7eae5",
            "23f32aa0fde34b8fb1d4a10f1fcdffae",
            "b3b9c308af414c7db0ceddf6d428a18b",
            "d3d88ec3aae84b83aad62442299b97f7",
            "1905126133ac49bea3e766d64731ee89",
            "97188eaebe834f88a28fa0d5add76086",
            "b5efbbba686e4236abf27ec395f269c7",
            "929e7d9569e74a1893195bfa58f6eff5"
          ]
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718907378287,
          "user_tz": 420,
          "elapsed": 3177320,
          "user": {
            "displayName": "Axel Sirota",
            "userId": "02089179879199828401"
          }
        },
        "outputId": "7a526f30-c1a5-41b0-9b10-05cf744eced5"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with rank=1, batch_size=8\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3dc91df8c8a4a70a710ace89b118af9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d1aa7c781b145119928bc8f39d99dc6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tf_keras/src/initializers/initializers.py:121: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n",
            "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainable parameters: 24674304\n",
            "Non-trainable parameters: 222903552\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db30b1652c8446a29aa79cff1c5ec1d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9f0e60e80694234af6a3f238291f86b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py:410: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\n",
            "Old behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n",
            "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \n",
            "New behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n",
            "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x7d9048323b50> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function infer_framework at 0x7d9048323b50> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "2500/2500 [==============================] - 325s 93ms/step - loss: 1.1027 - val_loss: 0.6510\n",
            "Epoch 2/2\n",
            "2500/2500 [==============================] - 206s 82ms/step - loss: 0.2451 - val_loss: 0.5664\n",
            "Training with rank=1, batch_size=64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 24674304\n",
            "Non-trainable parameters: 222903552\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdca1eb47cdd442a87d85cd37a69afa6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "313/313 [==============================] - 218s 462ms/step - loss: 4.1220 - val_loss: 0.8912\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 118s 376ms/step - loss: 0.5005 - val_loss: 0.6751\n",
            "Training with rank=1, batch_size=128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 24674304\n",
            "Non-trainable parameters: 222903552\n",
            "Epoch 1/2\n",
            "157/157 [==============================] - 213s 879ms/step - loss: 7.1623 - val_loss: 1.0697\n",
            "Epoch 2/2\n",
            "157/157 [==============================] - 111s 705ms/step - loss: 0.7077 - val_loss: 0.7991\n",
            "Training with rank=4, batch_size=8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 24674304\n",
            "Non-trainable parameters: 222903552\n",
            "Epoch 1/2\n",
            "2500/2500 [==============================] - 308s 93ms/step - loss: 1.0993 - val_loss: 0.6533\n",
            "Epoch 2/2\n",
            "2500/2500 [==============================] - 206s 82ms/step - loss: 0.2436 - val_loss: 0.5618\n",
            "Training with rank=4, batch_size=64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 24674304\n",
            "Non-trainable parameters: 222903552\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 218s 463ms/step - loss: 4.0889 - val_loss: 0.8932\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 118s 377ms/step - loss: 0.4996 - val_loss: 0.6727\n",
            "Training with rank=4, batch_size=128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 24674304\n",
            "Non-trainable parameters: 222903552\n",
            "Epoch 1/2\n",
            "157/157 [==============================] - 213s 879ms/step - loss: 7.2099 - val_loss: 1.0675\n",
            "Epoch 2/2\n",
            "157/157 [==============================] - 111s 705ms/step - loss: 0.7071 - val_loss: 0.7964\n",
            "Training with rank=16, batch_size=8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 24674304\n",
            "Non-trainable parameters: 222903552\n",
            "Epoch 1/2\n",
            "2500/2500 [==============================] - 305s 93ms/step - loss: 1.0985 - val_loss: 0.6624\n",
            "Epoch 2/2\n",
            "2500/2500 [==============================] - 205s 82ms/step - loss: 0.2457 - val_loss: 0.5577\n",
            "Training with rank=16, batch_size=64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 24674304\n",
            "Non-trainable parameters: 222903552\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 218s 464ms/step - loss: 4.1199 - val_loss: 0.8915\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 118s 377ms/step - loss: 0.5005 - val_loss: 0.6726\n",
            "Training with rank=16, batch_size=128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 24674304\n",
            "Non-trainable parameters: 222903552\n",
            "Epoch 1/2\n",
            "157/157 [==============================] - 213s 881ms/step - loss: 7.1746 - val_loss: 1.0715\n",
            "Epoch 2/2\n",
            "157/157 [==============================] - 111s 705ms/step - loss: 0.7075 - val_loss: 0.7987\n"
          ]
        }
      ],
      "source": [
        "import tf_keras\n",
        "import numpy as np\n",
        "from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "def count_params(model):\n",
        "    trainable_params = np.sum([np.prod(v.get_shape().as_list()) for v in model.trainable_weights])\n",
        "    non_trainable_params = np.sum([np.prod(v.get_shape().as_list()) for v in model.non_trainable_weights])\n",
        "    return trainable_params, non_trainable_params\n",
        "\n",
        "# Define training configurations\n",
        "ranks = [1, 4, 16]\n",
        "batch_sizes = [8, 64, 128]\n",
        "epochs = 2\n",
        "results = {}\n",
        "\n",
        "for rank in ranks:\n",
        "    for batch_size in batch_sizes:\n",
        "        print(f\"Training with rank={rank}, batch_size={batch_size}\")\n",
        "        model = TFAutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-base')\n",
        "        model.layers[0].trainable = False\n",
        "        model.layers[1].trainable = False\n",
        "        model.layers[2].trainable = False\n",
        "        model.layers[3] = LoRALayer(model.get_layer('lm_head'))\n",
        "\n",
        "        # Get the number of parameters\n",
        "        trainable_params, non_trainable_params = count_params(model)\n",
        "\n",
        "        # Print the number of parameters\n",
        "        print(f\"Trainable parameters: {trainable_params}\")\n",
        "        print(f\"Non-trainable parameters: {non_trainable_params}\")\n",
        "\n",
        "        # Update the batch size\n",
        "\n",
        "        train_dataset = dataset['train'].select(range(20000)).map(preprocess_data, batched=True)\n",
        "        test_dataset = dataset['test'].select(range(1000)).map(preprocess_data, batched=True)\n",
        "\n",
        "        train_dataset =  train_dataset.to_tf_dataset(\n",
        "            columns=['input_ids', 'attention_mask', 'decoder_input_ids'],\n",
        "            label_cols=['labels'],\n",
        "            shuffle=True,\n",
        "            batch_size=batch_size,\n",
        "            collate_fn=None\n",
        "        )\n",
        "\n",
        "        test_dataset = test_dataset.to_tf_dataset(\n",
        "            columns=['input_ids', 'attention_mask', 'decoder_input_ids'],\n",
        "            label_cols=['labels'],\n",
        "            shuffle=False,\n",
        "            batch_size=batch_size,\n",
        "            collate_fn=None\n",
        "        )\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(optimizer=tf_keras.optimizers.Adam(learning_rate=1e-2),\n",
        "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
        "\n",
        "        # Train the model\n",
        "        history = model.fit(train_dataset, validation_data=test_dataset, epochs=epochs)\n",
        "        results[(rank, batch_size)] = history.history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39af8cc2",
      "metadata": {
        "id": "39af8cc2"
      },
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5bdb1937",
      "metadata": {
        "id": "5bdb1937",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718907775745,
          "user_tz": 420,
          "elapsed": 363,
          "user": {
            "displayName": "Axel Sirota",
            "userId": "02089179879199828401"
          }
        },
        "outputId": "44253ab3-90c5-413b-fc2a-16260d15403d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for rank=1, batch_size=8\n",
            "{'loss': [1.1027005910873413, 0.24512912333011627], 'val_loss': [0.6509847044944763, 0.5663990378379822]}\n",
            "Results for rank=1, batch_size=64\n",
            "{'loss': [4.121983528137207, 0.5004836320877075], 'val_loss': [0.8912308216094971, 0.6750527024269104]}\n",
            "Results for rank=1, batch_size=128\n",
            "{'loss': [7.162280559539795, 0.7077131867408752], 'val_loss': [1.0696519613265991, 0.7991496920585632]}\n",
            "Results for rank=4, batch_size=8\n",
            "{'loss': [1.0993390083312988, 0.2436252385377884], 'val_loss': [0.6532699465751648, 0.5617694854736328]}\n",
            "Results for rank=4, batch_size=64\n",
            "{'loss': [4.088901519775391, 0.4996236264705658], 'val_loss': [0.8932406902313232, 0.6726864576339722]}\n",
            "Results for rank=4, batch_size=128\n",
            "{'loss': [7.20989990234375, 0.7070597410202026], 'val_loss': [1.0674861669540405, 0.7964359521865845]}\n",
            "Results for rank=16, batch_size=8\n",
            "{'loss': [1.0984629392623901, 0.24567732214927673], 'val_loss': [0.6624072194099426, 0.5576761364936829]}\n",
            "Results for rank=16, batch_size=64\n",
            "{'loss': [4.119870662689209, 0.5005176663398743], 'val_loss': [0.8914741277694702, 0.6726472973823547]}\n",
            "Results for rank=16, batch_size=128\n",
            "{'loss': [7.174552917480469, 0.7074552774429321], 'val_loss': [1.071483850479126, 0.7987415194511414]}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model for each configuration\n",
        "for (rank, batch_size), history in results.items():\n",
        "    print(f\"Results for rank={rank}, batch_size={batch_size}\")\n",
        "    print(history)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BGOUDcnz4ygs"
      },
      "id": "BGOUDcnz4ygs",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
