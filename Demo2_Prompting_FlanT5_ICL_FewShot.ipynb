{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2c0f4eb8",
      "metadata": {
        "id": "2c0f4eb8"
      },
      "source": [
        "# Enhanced Prompting with Flan-T5 using In-Context Learning and Few-Shot Pattern"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b876265b",
      "metadata": {
        "id": "b876265b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718820246705,
          "user_tz": 420,
          "elapsed": 6292,
          "user": {
            "displayName": "Axel Sirota",
            "userId": "02089179879199828401"
          }
        },
        "outputId": "02c207c6-6961-4eb2-87ca-08b1a1667923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "338d0ee5",
      "metadata": {
        "id": "338d0ee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437,
          "referenced_widgets": [
            "7b2b4e5562e44a889393f5c3f168af18",
            "a16da069c4d2432f90677250955e17f3",
            "0628cef0deee4df0a7fa1541b23c1ea5",
            "dbff14665b4e4a05b81503bb6cee5715",
            "5b14a70f50604e6698ef66fe6423e5c6",
            "5dff7321bd60421e967e331502f9c5ca",
            "580eb2fe8fc144d4b64f2eab2a57f93d",
            "c7e6170bf1d54073a7ca07e2705454da",
            "11a59dd9b68048ac9c40aea30967c08e",
            "29f521daddaf4cec9c59de4d012d56a6",
            "475faac32d04490bb096914e168b44d8",
            "ecbdf9e2d7fb44028c9240ea661ffc23",
            "2e8c2acc28c3432387d4789bd10222ae",
            "c16ea156dc8c40ef9243d5482313f608",
            "714dd49882634e83b7bb845f6f9468c6",
            "40a3dd19196d4519aab8fff5b5cceb6f",
            "01d309ca7f084d038724c9eb86aed937",
            "1429922b055c4fb880fc5f0ffc8a2b3f",
            "138e39cb0ba240acae02b865625781f8",
            "7af1c87fec4d437381564e4968cd5814",
            "03ca31f525694e47bcceda2b741bce91",
            "625a3d09322c47cb9b1b9ee85925ea90",
            "f70ce1e1e0364cb6a9be1da241e053aa",
            "24ff37f9414740aa86b0a05efea6825b",
            "d653d01b5c584d92aa13fccf9c54af72",
            "2719485896c2482393383b05ebd16a05",
            "f9eb3a733a8e414eae84d6d4358012e7",
            "85ca70ef083f43e8868b3cdce72847b1",
            "1ac700da0bd9406f9e361dade406bfdb",
            "664af228c50c43e1a477947c79cc33ce",
            "ff3c8f65c25a4366b2aafa7a21671233",
            "a3167b42fb874af08dfa20a747972185",
            "f608acf899d840c3b9e60009f6562e2f",
            "340dee70377f40b09a3a71fa1f07bcbd",
            "bdc251a831f147b79caf79a51e9e8542",
            "96596e403a154f598e32b098d5ac2ad0",
            "2bb9518209d4499b8c68a498bfd92316",
            "6f5e4c656a184d6e9486b099d520c0cc",
            "332cc8802a1f48ed9715f426234a5024",
            "9679714c6051486d8c15e319a1c6003d",
            "2d547ddce1f04570af6ed0e854ddf8ce",
            "03b8aa1f108f4c2f8e9fb73a48ee5596",
            "5cf0e37742b24559bd9845befe3c920d",
            "eb1f7dc22a8a4828bcf04262336f9124",
            "ba0cb418dda5442abeba865998b7f3ae",
            "e010c6eb46dc4ee8afcd96f341778d15",
            "76aee6d39d9a4090961954d21a1f9c14",
            "214b1b50a49543f9a10d6a69103f492e",
            "45c307a615784ba9a45ff21db02039bc",
            "3ca6065f5dd848a2afd5063220bced34",
            "5d18c72a40c14d0eb865fb80081199f4",
            "f97cc614283248978626783f58e3e5f4",
            "0702938518c946c9904985d85528d196",
            "4525532e4220471a8b8c579084c3ac3b",
            "cad83ae4f4614d1a82da9e38d1deb94d",
            "8149e311b9c34a30bddfa09da71ee49f",
            "2b07b0ec9c684b70836ca884988cc14e",
            "e7fdfd1c6d4f4a6bb857b43a5afe3547",
            "25b12f61bf1c4522abf7f63fd18b5b64",
            "23c2e2fec76d4af68c111df74690d28a",
            "101391840c6947239171d2bceef1d43c",
            "f026b9ce1abb4a4881b3fecc879da5f2",
            "7918c2af5ca144e0b7aa1bc588288229",
            "3a896f65e8a0468cbcda11ce7dc13c41",
            "5e21a86daabf435f9dcfd8208087b5ff",
            "fd7504736e4744c8b359f310c78bf641"
          ]
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718820288606,
          "user_tz": 420,
          "elapsed": 29786,
          "user": {
            "displayName": "Axel Sirota",
            "userId": "02089179879199828401"
          }
        },
        "outputId": "1203521f-2bf9-4c0e-c13d-255115f196e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b2b4e5562e44a889393f5c3f168af18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ecbdf9e2d7fb44028c9240ea661ffc23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f70ce1e1e0364cb6a9be1da241e053aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "340dee70377f40b09a3a71fa1f07bcbd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba0cb418dda5442abeba865998b7f3ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8149e311b9c34a30bddfa09da71ee49f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tf_keras/src/initializers/initializers.py:121: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n",
            "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b0ec416",
      "metadata": {
        "id": "2b0ec416"
      },
      "source": [
        "## Summarization with Few-Shot Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6e1328aa",
      "metadata": {
        "id": "6e1328aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718820430725,
          "user_tz": 420,
          "elapsed": 19979,
          "user": {
            "displayName": "Axel Sirota",
            "userId": "02089179879199828401"
          }
        },
        "outputId": "b78710b8-13fa-4a2d-be41-edec5053a213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: Carrots are a great source of vitamin A, which is crucial for maintaining healthy eyesight.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Here, we provide a few examples along with their summaries to help the model understand the pattern.\n",
        "\n",
        "# Few-shot examples\n",
        "few_shot_examples = [\n",
        "    \"Summarise: 'The quick brown fox jumps over the lazy dog. The dog was not amused by the fox's antics.' Summary: 'The fox jumped over the dog, who was not happy.'\",\n",
        "    \"Summarise: 'The rain in Spain stays mainly in the plain. It was a wet and rainy season in the Spanish plains.' Summary: 'It was a rainy season in the Spanish plains.'\"\n",
        "]\n",
        "\n",
        "# New prompt to summarize\n",
        "prompt = \"Summarise: 'Studies show that eating carrots helps improve vision. Carrots contain beta-carotene, a substance that the body converts into vitamin A, crucial for maintaining healthy eyesight.'\"\n",
        "\n",
        "# Combine examples and prompt\n",
        "combined_prompt = \"\\n\\n\".join(few_shot_examples + [prompt])\n",
        "\n",
        "# Generate inputs\n",
        "inputs = tokenizer(combined_prompt, return_tensors=\"tf\", max_length=512, truncation=True, padding=True)\n",
        "\n",
        "# Generate outputs\n",
        "outputs = model.generate(inputs[\"input_ids\"], max_length=150, num_beams=5, early_stopping=True)\n",
        "\n",
        "# Decode and print the summary\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e9d081a",
      "metadata": {
        "id": "8e9d081a"
      },
      "source": [
        "## Translation with Few-Shot Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "df94fbee",
      "metadata": {
        "id": "df94fbee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718820512848,
          "user_tz": 420,
          "elapsed": 9962,
          "user": {
            "displayName": "Axel Sirota",
            "userId": "02089179879199828401"
          }
        },
        "outputId": "fd0d2a3e-d350-4c10-c2ea-455a8a68b796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation: El queso es delicioso.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Here, we provide a few examples along with their translations to help the model understand the pattern.\n",
        "\n",
        "# Few-shot examples\n",
        "few_shot_examples = [\n",
        "    \"translate English to Spanish: 'The cat sits on the mat.' Translation: 'El gato se sienta en la alfombra.'\",\n",
        "    \"translate English to Spanish: 'The sun is shining brightly.' Translation: 'El sol brilla intensamente.'\"\n",
        "]\n",
        "\n",
        "# New prompt to translate\n",
        "translation_prompt = \"translate English to Spanish: 'Cheese is delicious.'\"\n",
        "\n",
        "# Combine examples and prompt\n",
        "combined_translation_prompt = \"\\n\\n\".join(few_shot_examples + [translation_prompt])\n",
        "\n",
        "# Prepare inputs and generate outputs\n",
        "translation_inputs = tokenizer(combined_translation_prompt, return_tensors=\"tf\", max_length=512, truncation=True, padding=True)\n",
        "translation_outputs = model.generate(translation_inputs[\"input_ids\"], max_length=40, num_beams=5, early_stopping=True)\n",
        "\n",
        "# Decode and display the translation\n",
        "print(tokenizer.decode(translation_outputs[0], skip_special_tokens=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb551e91",
      "metadata": {
        "id": "fb551e91"
      },
      "source": [
        "## Q&A with In-Context Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "acc290a8",
      "metadata": {
        "id": "acc290a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718820599086,
          "user_tz": 420,
          "elapsed": 9586,
          "user": {
            "displayName": "Axel Sirota",
            "userId": "02089179879199828401"
          }
        },
        "outputId": "6043957b-c18c-44f0-a575-acf40e5d1440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 'Mount Everest\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Here, we provide a few examples along with their answers to help the model understand the pattern.\n",
        "\n",
        "# Few-shot examples\n",
        "few_shot_examples = [\n",
        "    \"The Great Wall of China is over 13,000 miles long. question: 'How long is the Great Wall of China?' answer: 'The Great Wall of China is over 13,000 miles long.'\",\n",
        "    \"The capital of France is Paris. question: 'What is the capital of France?' answer: 'The capital of France is Paris.'\"\n",
        "]\n",
        "\n",
        "# New context and question\n",
        "context_question = \"Mount Everest is the highest mountain in the world. question: 'What is the highest mountain in the world?'\"\n",
        "\n",
        "# Combine examples and prompt\n",
        "combined_qa_prompt = \"\\n\\n\".join(few_shot_examples + [context_question])\n",
        "\n",
        "# Generate inputs\n",
        "question_inputs = tokenizer(combined_qa_prompt, return_tensors=\"tf\", max_length=512, truncation=True, padding=True)\n",
        "\n",
        "# Generate outputs\n",
        "question_outputs = model.generate(question_inputs[\"input_ids\"], max_length=50, num_beams=5, early_stopping=True)\n",
        "\n",
        "# Decode and print the answer\n",
        "print(tokenizer.decode(question_outputs[0], skip_special_tokens=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yCAI2pNpsM5X"
      },
      "id": "yCAI2pNpsM5X",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
